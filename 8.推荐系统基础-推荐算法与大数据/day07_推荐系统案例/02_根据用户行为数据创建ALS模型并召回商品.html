
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>02_根据用户行为数据创建ALS模型并召回商品 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="03_CTR预估数据准备.html" />
    
    
    <link rel="prev" href="01_个性化电商广告推荐系统介绍.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    简介
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">一 推荐系统简介</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../day01_推荐系统介绍/01_推荐系统简介.html">
            
                <a href="../day01_推荐系统介绍/01_推荐系统简介.html">
            
                    
                    1.1_推荐系统简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../day01_推荐系统介绍/02_推荐系统架构设计.html">
            
                <a href="../day01_推荐系统介绍/02_推荐系统架构设计.html">
            
                    
                    1.2_推荐系统架构设计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../day01_推荐系统介绍/03_推荐算法.html">
            
                <a href="../day01_推荐系统介绍/03_推荐算法.html">
            
                    
                    1.3_推荐算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../day01_推荐系统介绍/04_案例--基于协同过滤的电影推荐.html">
            
                <a href="../day01_推荐系统介绍/04_案例--基于协同过滤的电影推荐.html">
            
                    
                    1.4_案例--基于协同过滤的电影推荐
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../day01_推荐系统介绍/07_ 推荐系统评估.html">
            
                <a href="../day01_推荐系统介绍/07_ 推荐系统评估.html">
            
                    
                    1.5_推荐系统评估
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../day01_推荐系统介绍/08_ 推荐系统冷启动问题.html">
            
                <a href="../day01_推荐系统介绍/08_ 推荐系统冷启动问题.html">
            
                    
                    1.6_推荐系统的冷启动问题
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">二 推荐系统算法</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../day02_推荐算法/01_基于模型的协同过滤推荐.html">
            
                <a href="../day02_推荐算法/01_基于模型的协同过滤推荐.html">
            
                    
                    2.1_基于模型的协同过滤推荐
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../day02_推荐算法/03_基于回归模型的协同过滤推荐.html">
            
                <a href="../day02_推荐算法/03_基于回归模型的协同过滤推荐.html">
            
                    
                    2.2_基于回归模型的协同过滤推荐
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../day02_推荐算法/04_基于矩阵分解的协同过滤推荐.html">
            
                <a href="../day02_推荐算法/04_基于矩阵分解的协同过滤推荐.html">
            
                    
                    2.3_基于矩阵分解的协同过滤推荐
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="../day02_推荐算法/05_LFM算法实现.html">
            
                <a href="../day02_推荐算法/05_LFM算法实现.html">
            
                    
                    2.4_LFM算法实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.5" data-path="../day02_推荐算法/06_BiasSVD算法实现.html">
            
                <a href="../day02_推荐算法/06_BiasSVD算法实现.html">
            
                    
                    2.5_BiasSVD算法实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.6" data-path="../day02_推荐算法/07_基于内容的推荐算法.html">
            
                <a href="../day02_推荐算法/07_基于内容的推荐算法.html">
            
                    
                    2.6_基于内容的推荐算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.7" data-path="../day02_推荐算法/08_物品画像.html">
            
                <a href="../day02_推荐算法/08_物品画像.html">
            
                    
                    2.7_电影推荐(ContentBased)物品画像
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.8" data-path="../day02_推荐算法/09_用户画像.html">
            
                <a href="../day02_推荐算法/09_用户画像.html">
            
                    
                    2.8_电影推荐(ContentBased)用户画像
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.9" data-path="../day02_推荐算法/10_TOPN用户推荐.html">
            
                <a href="../day02_推荐算法/10_TOPN用户推荐.html">
            
                    
                    2.9_电影推荐(ContentBased)TOP-N用户推荐
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">三 Hadoop</li>
        
        
    

    
        
        <li class="header">3.1 Hadoop概述</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="../day03_Hadoop/ha1.1.html">
            
                <a href="../day03_Hadoop/ha1.1.html">
            
                    
                    01_什么是Hadoop
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="../day03_Hadoop/ha1.2.html">
            
                <a href="../day03_Hadoop/ha1.2.html">
            
                    
                    02_Hadoop核心组件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="../day03_Hadoop/ha1.3.html">
            
                <a href="../day03_Hadoop/ha1.3.html">
            
                    
                    03_Hadoop优势
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">3.2 分布式文件系统HDFS</li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="../day03_Hadoop/ha2.1.html">
            
                <a href="../day03_Hadoop/ha2.1.html">
            
                    
                    01_HDFS的使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="../day03_Hadoop/ha2.2.html">
            
                <a href="../day03_Hadoop/ha2.2.html">
            
                    
                    02_HDFS Shell操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="../day03_Hadoop/ha2.3.html">
            
                <a href="../day03_Hadoop/ha2.3.html">
            
                    
                    03_HDFS设计思路
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="../day03_Hadoop/ha2.4.html">
            
                <a href="../day03_Hadoop/ha2.4.html">
            
                    
                    04_HDFS架构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="6.5" data-path="../day03_Hadoop/ha2.5.html">
            
                <a href="../day03_Hadoop/ha2.5.html">
            
                    
                    05_HDFS环境搭建
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">3.3 YARN&MapReduce</li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="../day03_Hadoop/ha3.1.html">
            
                <a href="../day03_Hadoop/ha3.1.html">
            
                    
                    01_资源调度框架YARN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="../day03_Hadoop/ha3.2.html">
            
                <a href="../day03_Hadoop/ha3.2.html">
            
                    
                    02_分布式计算框架MapReduce
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.3" data-path="../day03_Hadoop/ha3.3.html">
            
                <a href="../day03_Hadoop/ha3.3.html">
            
                    
                    03_MapReduce实战
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="../day03_Hadoop/ha3.5.html">
            
                <a href="../day03_Hadoop/ha3.5.html">
            
                    
                    04_MapReduce原理
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">3.4 Hadoop概念扩展</li>
        
        
    
        <li class="chapter " data-level="8.1" data-path="../day03_Hadoop/ha4.1.html">
            
                <a href="../day03_Hadoop/ha4.1.html">
            
                    
                    01_Hadoop生态系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="../day03_Hadoop/ha4.2.html">
            
                <a href="../day03_Hadoop/ha4.2.html">
            
                    
                    02_HDFS读写流程&高可用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="8.3" data-path="../day03_Hadoop/ha4.3.html">
            
                <a href="../day03_Hadoop/ha4.3.html">
            
                    
                    03_Hadoop发行版选择
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">四 Hive</li>
        
        
    
        <li class="chapter " data-level="9.1" data-path="../Hive&HBase/01_hive介绍.html">
            
                <a href="../Hive&HBase/01_hive介绍.html">
            
                    
                    01_Hive基本概念
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="9.2" data-path="../Hive&HBase/02_hive的shell操作.html">
            
                <a href="../Hive&HBase/02_hive的shell操作.html">
            
                    
                    02_Hive的shell操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="9.3" data-path="../Hive&HBase/03_Hive的函数和自定义函数.html">
            
                <a href="../Hive&HBase/03_Hive的函数和自定义函数.html">
            
                    
                    03_Hive的函数和自定义函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="9.4" data-path="../Hive&HBase/04_hive综合案例.html">
            
                <a href="../Hive&HBase/04_hive综合案例.html">
            
                    
                    04_Hive综合案例
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">五 HBase</li>
        
        
    
        <li class="chapter " data-level="10.1" data-path="../Hive&HBase/05_hBase简介与环境部署.html">
            
                <a href="../Hive&HBase/05_hBase简介与环境部署.html">
            
                    
                    01_HBase简介与环境部署
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="10.2" data-path="../Hive&HBase/06_hbase数据模型.html">
            
                <a href="../Hive&HBase/06_hbase数据模型.html">
            
                    
                    02_Hbase数据模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="10.3" data-path="../Hive&HBase/07_hbase的安装与shell操作.html">
            
                <a href="../Hive&HBase/07_hbase的安装与shell操作.html">
            
                    
                    03_Hbase的安装与shell操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="10.4" data-path="../Hive&HBase/08_HappyBase操作HBase.html">
            
                <a href="../Hive&HBase/08_HappyBase操作HBase.html">
            
                    
                    04_HappyBase操作HBase
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="10.5" data-path="../Hive&HBase/10_HBase组件.html">
            
                <a href="../Hive&HBase/10_HBase组件.html">
            
                    
                    05_HBase组件
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">六 Spark Core</li>
        
        
    
        <li class="chapter " data-level="11.1" data-path="../day05_Spark_core/spark_core_1.html">
            
                <a href="../day05_Spark_core/spark_core_1.html">
            
                    
                    01_Spark入门
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="11.2" data-path="../day05_Spark_core/spark_core_2.html">
            
                <a href="../day05_Spark_core/spark_core_2.html">
            
                    
                    02_RDD概念介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="11.3" data-path="../day05_Spark_core/spark_core_3.html">
            
                <a href="../day05_Spark_core/spark_core_3.html">
            
                    
                    03_RDD常用算子练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="11.4" data-path="../day05_Spark_core/spark_core_4.html">
            
                <a href="../day05_Spark_core/spark_core_4.html">
            
                    
                    04_Spark-Core实战案例_pv&uv统计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="11.5" data-path="../day05_Spark_core/spark_core_5.html">
            
                <a href="../day05_Spark_core/spark_core_5.html">
            
                    
                    05_Spark-Core实战_ip统计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="11.6" data-path="../day05_Spark_core/spark_core_6.html">
            
                <a href="../day05_Spark_core/spark_core_6.html">
            
                    
                    06_Spark安装部署&standalone模式介绍
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">七 Spark SQL</li>
        
        
    
        <li class="chapter " data-level="12.1" data-path="../day06_Spark_sql&Spark_streaming/s1.1.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/s1.1.html">
            
                    
                    01_Spark SQL简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="12.2" data-path="../day06_Spark_sql&Spark_streaming/s1.2.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/s1.2.html">
            
                    
                    02_DataFrame介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="12.3" data-path="../day06_Spark_sql&Spark_streaming/s1.3.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/s1.3.html">
            
                    
                    03_Spark SQL 处理JSON数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="12.4" data-path="../day06_Spark_sql&Spark_streaming/s1.4.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/s1.4.html">
            
                    
                    04Spark SQL案例数据清洗
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">八 Spark Streaming</li>
        
        
    
        <li class="chapter " data-level="13.1" data-path="../day06_Spark_sql&Spark_streaming/ss1.1.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/ss1.1.html">
            
                    
                    05_Spark Streaming简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="13.2" data-path="../day06_Spark_sql&Spark_streaming/ss1.2.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/ss1.2.html">
            
                    
                    06_Spark Streaming实现WordCount
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="13.3" data-path="../day06_Spark_sql&Spark_streaming/ss1.3.html">
            
                <a href="../day06_Spark_sql&Spark_streaming/ss1.3.html">
            
                    
                    07_Spark Steaming的状态操作
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">九 电商推荐案例</li>
        
        
    
        <li class="chapter " data-level="14.1" data-path="01_个性化电商广告推荐系统介绍.html">
            
                <a href="01_个性化电商广告推荐系统介绍.html">
            
                    
                    01_个性化电商广告推荐系统介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="14.2" data-path="02_根据用户行为数据创建ALS模型并召回商品.html">
            
                <a href="02_根据用户行为数据创建ALS模型并召回商品.html">
            
                    
                    02_根据用户行为数据创建ALS模型并召回商品
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="14.3" data-path="03_CTR预估数据准备.html">
            
                <a href="03_CTR预估数据准备.html">
            
                    
                    03_CTR预估数据准备
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="14.4" data-path="04_逻辑回归实现CTR预估.html">
            
                <a href="04_逻辑回归实现CTR预估.html">
            
                    
                    04_逻辑回归(LR)实现CTR预估
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="14.5" data-path="05_离线推荐处理.html">
            
                <a href="05_离线推荐处理.html">
            
                    
                    05_离线推荐处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="14.6" data-path="06_实时推荐.html">
            
                <a href="06_实时推荐.html">
            
                    
                    06_实时推荐
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >02_根据用户行为数据创建ALS模型并召回商品</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id="&#x4E8C;-&#x6839;&#x636E;&#x7528;&#x6237;&#x884C;&#x4E3A;&#x6570;&#x636E;&#x521B;&#x5EFA;als&#x6A21;&#x578B;&#x5E76;&#x53EC;&#x56DE;&#x5546;&#x54C1;">&#x4E8C; &#x6839;&#x636E;&#x7528;&#x6237;&#x884C;&#x4E3A;&#x6570;&#x636E;&#x521B;&#x5EFA;ALS&#x6A21;&#x578B;&#x5E76;&#x53EC;&#x56DE;&#x5546;&#x54C1;</h2>
<h3 id="20-&#x7528;&#x6237;&#x884C;&#x4E3A;&#x6570;&#x636E;&#x62C6;&#x5206;">2.0 &#x7528;&#x6237;&#x884C;&#x4E3A;&#x6570;&#x636E;&#x62C6;&#x5206;</h3>
<ul>
<li><p>&#x65B9;&#x4FBF;&#x7EC3;&#x4E60;&#x53EF;&#x4EE5;&#x5BF9;&#x6570;&#x636E;&#x505A;&#x62C6;&#x5206;&#x5904;&#x7406;</p>
<ul>
<li>pandas&#x7684;&#x6570;&#x636E;&#x5206;&#x6279;&#x8BFB;&#x53D6;  chunk &#x539A;&#x539A;&#x7684;&#x4E00;&#x5757; &#x76F8;&#x5F53;&#x5927;&#x7684;&#x6570;&#x91CF;&#x6216;&#x90E8;&#x5206;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
reader = pd.read_csv(<span class="hljs-string">&apos;behavior_log.csv&apos;</span>,chunksize=<span class="hljs-number">100</span>,iterator=<span class="hljs-keyword">True</span>)
count = <span class="hljs-number">0</span>;
<span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> reader:
    count += <span class="hljs-number">1</span>
    <span class="hljs-keyword">if</span> count ==<span class="hljs-number">1</span>:
        chunk.to_csv(<span class="hljs-string">&apos;test4.csv&apos;</span>,index = <span class="hljs-keyword">False</span>)
    <span class="hljs-keyword">elif</span> count&gt;<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> count&lt;<span class="hljs-number">1000</span>:
        chunk.to_csv(<span class="hljs-string">&apos;test4.csv&apos;</span>,index = <span class="hljs-keyword">False</span>, mode = <span class="hljs-string">&apos;a&apos;</span>,header = <span class="hljs-keyword">False</span>)
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">break</span>
pd.read_csv(<span class="hljs-string">&apos;test4.csv&apos;</span>)
</code></pre>
</li>
</ul>
<h3 id="21-&#x9884;&#x5904;&#x7406;behaviorlog&#x6570;&#x636E;&#x96C6;">2.1 &#x9884;&#x5904;&#x7406;behavior_log&#x6570;&#x636E;&#x96C6;</h3>
<ul>
<li>&#x521B;&#x5EFA;spark session</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> os
<span class="hljs-comment"># &#x914D;&#x7F6E;spark driver&#x548C;pyspark&#x8FD0;&#x884C;&#x65F6;&#xFF0C;&#x6240;&#x4F7F;&#x7528;&#x7684;python&#x89E3;&#x91CA;&#x5668;&#x8DEF;&#x5F84;</span>
PYSPARK_PYTHON = <span class="hljs-string">&quot;/miniconda2/envs/py365/bin/python&quot;</span>
JAVA_HOME=<span class="hljs-string">&apos;/root/bigdata/jdk&apos;</span>
SPARK_HOME = <span class="hljs-string">&quot;/root/bigdata/spark&quot;</span>
<span class="hljs-comment"># &#x5F53;&#x5B58;&#x5728;&#x591A;&#x4E2A;&#x7248;&#x672C;&#x65F6;&#xFF0C;&#x4E0D;&#x6307;&#x5B9A;&#x5F88;&#x53EF;&#x80FD;&#x4F1A;&#x5BFC;&#x81F4;&#x51FA;&#x9519;</span>
os.environ[<span class="hljs-string">&quot;PYSPARK_PYTHON&quot;</span>] = PYSPARK_PYTHON
os.environ[<span class="hljs-string">&quot;PYSPARK_DRIVER_PYTHON&quot;</span>] = PYSPARK_PYTHON
os.environ[<span class="hljs-string">&apos;JAVA_HOME&apos;</span>]=JAVA_HOME
os.environ[<span class="hljs-string">&quot;SPARK_HOME&quot;</span>] = SPARK_HOME
<span class="hljs-comment"># spark&#x914D;&#x7F6E;&#x4FE1;&#x606F;</span>
<span class="hljs-keyword">from</span> pyspark <span class="hljs-keyword">import</span> SparkConf
<span class="hljs-keyword">from</span> pyspark.sql <span class="hljs-keyword">import</span> SparkSession

SPARK_APP_NAME = <span class="hljs-string">&quot;preprocessingBehaviorLog&quot;</span>
SPARK_URL = <span class="hljs-string">&quot;spark://192.168.19.137:7077&quot;</span>

conf = SparkConf()    <span class="hljs-comment"># &#x521B;&#x5EFA;spark config&#x5BF9;&#x8C61;</span>
config = (
    (<span class="hljs-string">&quot;spark.app.name&quot;</span>, SPARK_APP_NAME),    <span class="hljs-comment"># &#x8BBE;&#x7F6E;&#x542F;&#x52A8;&#x7684;spark&#x7684;app&#x540D;&#x79F0;&#xFF0C;&#x6CA1;&#x6709;&#x63D0;&#x4F9B;&#xFF0C;&#x5C06;&#x968F;&#x673A;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x540D;&#x79F0;</span>
    (<span class="hljs-string">&quot;spark.executor.memory&quot;</span>, <span class="hljs-string">&quot;6g&quot;</span>),    <span class="hljs-comment"># &#x8BBE;&#x7F6E;&#x8BE5;app&#x542F;&#x52A8;&#x65F6;&#x5360;&#x7528;&#x7684;&#x5185;&#x5B58;&#x7528;&#x91CF;&#xFF0C;&#x9ED8;&#x8BA4;1g</span>
    (<span class="hljs-string">&quot;spark.master&quot;</span>, SPARK_URL),    <span class="hljs-comment"># spark master&#x7684;&#x5730;&#x5740;</span>
    (<span class="hljs-string">&quot;spark.executor.cores&quot;</span>, <span class="hljs-string">&quot;4&quot;</span>),    <span class="hljs-comment"># &#x8BBE;&#x7F6E;spark executor&#x4F7F;&#x7528;&#x7684;CPU&#x6838;&#x5FC3;&#x6570;</span>
    <span class="hljs-comment"># &#x4EE5;&#x4E0B;&#x4E09;&#x9879;&#x914D;&#x7F6E;&#xFF0C;&#x53EF;&#x4EE5;&#x63A7;&#x5236;&#x6267;&#x884C;&#x5668;&#x6570;&#x91CF;</span>
<span class="hljs-comment">#     (&quot;spark.dynamicAllocation.enabled&quot;, True),</span>
<span class="hljs-comment">#     (&quot;spark.dynamicAllocation.initialExecutors&quot;, 1),    # 1&#x4E2A;&#x6267;&#x884C;&#x5668;</span>
<span class="hljs-comment">#     (&quot;spark.shuffle.service.enabled&quot;, True)</span>
<span class="hljs-comment">#     (&apos;spark.sql.pivotMaxValues&apos;, &apos;99999&apos;),  # &#x5F53;&#x9700;&#x8981;pivot DF&#xFF0C;&#x4E14;&#x503C;&#x5F88;&#x591A;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x4FEE;&#x6539;&#xFF0C;&#x9ED8;&#x8BA4;&#x662F;10000</span>
)
<span class="hljs-comment"># &#x67E5;&#x770B;&#x66F4;&#x8BE6;&#x7EC6;&#x914D;&#x7F6E;&#x53CA;&#x8BF4;&#x660E;&#xFF1A;https://spark.apache.org/docs/latest/configuration.html</span>

conf.setAll(config)

<span class="hljs-comment"># &#x5229;&#x7528;config&#x5BF9;&#x8C61;&#xFF0C;&#x521B;&#x5EFA;spark session</span>
spark = SparkSession.builder.config(conf=conf).getOrCreate()
</code></pre>
<ul>
<li>&#x4ECE;hdfs&#x4E2D;&#x52A0;&#x8F7D;csv&#x6587;&#x4EF6;&#x4E3A;DataFrame</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4ECE;hdfs&#x52A0;&#x8F7D;CSV&#x6587;&#x4EF6;&#x4E3A;DataFrame</span>
df = spark.read.csv(<span class="hljs-string">&quot;hdfs://localhost:9000/data/behavior_log.csv&quot;</span>, header=<span class="hljs-keyword">True</span>)
df.show()    <span class="hljs-comment"># &#x67E5;&#x770B;dataframe&#xFF0C;&#x9ED8;&#x8BA4;&#x663E;&#x793A;&#x524D;20&#x6761;</span>
<span class="hljs-comment"># &#x5927;&#x81F4;&#x67E5;&#x770B;&#x4E00;&#x4E0B;&#x6570;&#x636E;&#x7C7B;&#x578B;</span>
df.printSchema()    <span class="hljs-comment"># &#x6253;&#x5370;&#x5F53;&#x524D;dataframe&#x7684;&#x7ED3;&#x6784;</span>
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">+------+----------+----+-----+------+
|  user|time_stamp|btag| cate| brand|
+------+----------+----+-----+------+
|558157|1493741625|  pv| 6250| 91286|
|558157|1493741626|  pv| 6250| 91286|
|558157|1493741627|  pv| 6250| 91286|
|728690|1493776998|  pv|11800| 62353|
|332634|1493809895|  pv| 1101|365477|
|857237|1493816945|  pv| 1043|110616|
|619381|1493774638|  pv|  385|428950|
|467042|1493772641|  pv| 8237|301299|
|467042|1493772644|  pv| 8237|301299|
|991528|1493780710|  pv| 7270|274795|
|991528|1493780712|  pv| 7270|274795|
|991528|1493780712|  pv| 7270|274795|
|991528|1493780712|  pv| 7270|274795|
|991528|1493780714|  pv| 7270|274795|
|991528|1493780765|  pv| 7270|274795|
|991528|1493780714|  pv| 7270|274795|
|991528|1493780765|  pv| 7270|274795|
|991528|1493780764|  pv| 7270|274795|
|991528|1493780633|  pv| 7270|274795|
|991528|1493780764|  pv| 7270|274795|
+------+----------+----+-----+------+
only showing top 20 rows

root
 |-- user: string (nullable = true)
 |-- time_stamp: string (nullable = true)
 |-- btag: string (nullable = true)
 |-- cate: string (nullable = true)
 |-- brand: string (nullable = true)
</code></pre>
<ul>
<li>&#x4ECE;hdfs&#x52A0;&#x8F7D;&#x6570;&#x636E;&#x4E3A;dataframe&#xFF0C;&#x5E76;&#x8BBE;&#x7F6E;&#x7ED3;&#x6784;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> StructType, StructField, StringType, IntegerType, LongType
<span class="hljs-comment"># &#x6784;&#x5EFA;&#x7ED3;&#x6784;&#x5BF9;&#x8C61;</span>
schema = StructType([
    StructField(<span class="hljs-string">&quot;userId&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;timestamp&quot;</span>, LongType()),
    StructField(<span class="hljs-string">&quot;btag&quot;</span>, StringType()),
    StructField(<span class="hljs-string">&quot;cateId&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;brandId&quot;</span>, IntegerType())
])
<span class="hljs-comment"># &#x4ECE;hdfs&#x52A0;&#x8F7D;&#x6570;&#x636E;&#x4E3A;dataframe&#xFF0C;&#x5E76;&#x8BBE;&#x7F6E;&#x7ED3;&#x6784;</span>
behavior_log_df = spark.read.csv(<span class="hljs-string">&quot;hdfs://localhost:9000/data/behavior_log.csv&quot;</span>, header=<span class="hljs-keyword">True</span>, schema=schema)
behavior_log_df.show()
behavior_log_df.count()
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">+------+----------+----+------+-------+
|userId| timestamp|btag|cateId|brandId|
+------+----------+----+------+-------+
|558157|1493741625|  pv|  6250|  91286|
|558157|1493741626|  pv|  6250|  91286|
|558157|1493741627|  pv|  6250|  91286|
|728690|1493776998|  pv| 11800|  62353|
|332634|1493809895|  pv|  1101| 365477|
|857237|1493816945|  pv|  1043| 110616|
|619381|1493774638|  pv|   385| 428950|
|467042|1493772641|  pv|  8237| 301299|
|467042|1493772644|  pv|  8237| 301299|
|991528|1493780710|  pv|  7270| 274795|
|991528|1493780712|  pv|  7270| 274795|
|991528|1493780712|  pv|  7270| 274795|
|991528|1493780712|  pv|  7270| 274795|
|991528|1493780714|  pv|  7270| 274795|
|991528|1493780765|  pv|  7270| 274795|
|991528|1493780714|  pv|  7270| 274795|
|991528|1493780765|  pv|  7270| 274795|
|991528|1493780764|  pv|  7270| 274795|
|991528|1493780633|  pv|  7270| 274795|
|991528|1493780764|  pv|  7270| 274795|
+------+----------+----+------+-------+
only showing top 20 rows

root
 |-- userId: integer (nullable = true)
 |-- timestamp: long (nullable = true)
 |-- btag: string (nullable = true)
 |-- cateId: integer (nullable = true)
 |-- brandId: integer (nullable = true)
</code></pre>
<ul>
<li>&#x5206;&#x6790;&#x6570;&#x636E;&#x96C6;&#x5B57;&#x6BB5;&#x7684;&#x7C7B;&#x578B;&#x548C;&#x683C;&#x5F0F;<ul>
<li>&#x67E5;&#x770B;&#x662F;&#x5426;&#x6709;&#x7A7A;&#x503C;</li>
<li>&#x67E5;&#x770B;&#x6BCF;&#x5217;&#x6570;&#x636E;&#x7684;&#x7C7B;&#x578B;</li>
<li>&#x67E5;&#x770B;&#x6BCF;&#x5217;&#x6570;&#x636E;&#x7684;&#x7C7B;&#x522B;&#x60C5;&#x51B5;</li>
</ul>
</li>
</ul>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;&#x67E5;&#x770B;userId&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A;&quot;</span>, behavior_log_df.groupBy(<span class="hljs-string">&quot;userId&quot;</span>).count().count())
<span class="hljs-comment"># &#x7EA6;113w&#x7528;&#x6237;</span>
<span class="hljs-comment">#&#x6CE8;&#x610F;&#xFF1A;behavior_log_df.groupBy(&quot;userId&quot;).count()  &#x8FD4;&#x56DE;&#x7684;&#x662F;&#x4E00;&#x4E2A;dataframe&#xFF0C;&#x8FD9;&#x91CC;&#x7684;count&#x8BA1;&#x7B97;&#x7684;&#x662F;&#x6BCF;&#x4E00;&#x4E2A;&#x5206;&#x7EC4;&#x7684;&#x4E2A;&#x6570;&#xFF0C;&#x4F46;&#x5F53;&#x524D;&#x8FD8;&#x6CA1;&#x6709;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;</span>
<span class="hljs-comment"># &#x5F53;&#x8C03;&#x7528;df.count()&#x65F6;&#x624D;&#x5F00;&#x59CB;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;&#xFF0C;&#x8FD9;&#x91CC;&#x7684;count&#x8BA1;&#x7B97;&#x7684;&#x662F;dataframe&#x7684;&#x6761;&#x76EE;&#x6570;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x5171;&#x6709;&#x591A;&#x5C11;&#x4E2A;&#x5206;&#x7EC4;</span>
</code></pre>
<pre><code class="lang-shell">&#x67E5;&#x770B;user&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A; 1136340
</code></pre>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;&#x67E5;&#x770B;btag&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A;&quot;</span>, behavior_log_df.groupBy(<span class="hljs-string">&quot;btag&quot;</span>).count().collect())    <span class="hljs-comment"># collect&#x4F1A;&#x628A;&#x8BA1;&#x7B97;&#x7ED3;&#x679C;&#x5168;&#x90E8;&#x52A0;&#x8F7D;&#x5230;&#x5185;&#x5B58;&#xFF0C;&#x8C28;&#x614E;&#x4F7F;&#x7528;</span>
<span class="hljs-comment"># &#x53EA;&#x6709;&#x56DB;&#x79CD;&#x7C7B;&#x578B;&#x6570;&#x636E;&#xFF1A;pv&#x3001;fav&#x3001;cart&#x3001;buy</span>
<span class="hljs-comment"># &#x8FD9;&#x91CC;&#x7531;&#x4E8E;&#x7C7B;&#x578B;&#x53EA;&#x6709;&#x56DB;&#x4E2A;&#xFF0C;&#x6240;&#x4EE5;&#x76F4;&#x63A5;&#x4F7F;&#x7528;collect&#xFF0C;&#x628A;&#x6570;&#x636E;&#x5168;&#x90E8;&#x52A0;&#x8F7D;&#x51FA;&#x6765;</span>
</code></pre>
<pre><code class="lang-shell">&#x67E5;&#x770B;btag&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A; [Row(btag=&apos;buy&apos;, count=9115919), Row(btag=&apos;fav&apos;, count=9301837), Row(btag=&apos;cart&apos;, count=15946033), Row(btag=&apos;pv&apos;, count=688904345)]
</code></pre>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;&#x67E5;&#x770B;cateId&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A;&quot;</span>, behavior_log_df.groupBy(<span class="hljs-string">&quot;cateId&quot;</span>).count().count())
<span class="hljs-comment"># &#x7EA6;12968&#x7C7B;&#x522B;id</span>
</code></pre>
<pre><code class="lang-shell">&#x67E5;&#x770B;cateId&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A; 12968
</code></pre>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;&#x67E5;&#x770B;brandId&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A;&quot;</span>, behavior_log_df.groupBy(<span class="hljs-string">&quot;brandId&quot;</span>).count().count())
<span class="hljs-comment"># &#x7EA6;460561&#x54C1;&#x724C;id</span>
</code></pre>
<pre><code class="lang-shell">&#x67E5;&#x770B;brandId&#x7684;&#x6570;&#x636E;&#x60C5;&#x51B5;&#xFF1A; 460561
</code></pre>
<pre><code class="lang-python">print(<span class="hljs-string">&quot;&#x5224;&#x65AD;&#x6570;&#x636E;&#x662F;&#x5426;&#x6709;&#x7A7A;&#x503C;&#xFF1A;&quot;</span>, behavior_log_df.count(), behavior_log_df.dropna().count())
<span class="hljs-comment"># &#x7EA6;7&#x4EBF;&#x6761;&#x76EE;723268134 723268134</span>
<span class="hljs-comment"># &#x672C;&#x6570;&#x636E;&#x96C6;&#x65E0;&#x7A7A;&#x503C;&#x6761;&#x76EE;&#xFF0C;&#x53EF;&#x653E;&#x5FC3;&#x5904;&#x7406;</span>
</code></pre>
<pre><code class="lang-shell">&#x5224;&#x65AD;&#x6570;&#x636E;&#x662F;&#x5426;&#x6709;&#x7A7A;&#x503C;&#xFF1A; 723268134 723268134
</code></pre>
<ul>
<li>pivot&#x900F;&#x89C6;&#x64CD;&#x4F5C;&#xFF0C;&#x628A;&#x67D0;&#x5217;&#x91CC;&#x7684;&#x5B57;&#x6BB5;&#x503C;&#x8F6C;&#x6362;&#x6210;&#x884C;&#x5E76;&#x8FDB;&#x884C;&#x805A;&#x5408;&#x8FD0;&#x7B97;(pyspark.sql.GroupedData.pivot)<ul>
<li>&#x5982;&#x679C;&#x900F;&#x89C6;&#x7684;&#x5B57;&#x6BB5;&#x4E2D;&#x7684;&#x4E0D;&#x540C;&#x5C5E;&#x6027;&#x503C;&#x8D85;&#x8FC7;10000&#x4E2A;&#xFF0C;&#x5219;&#x9700;&#x8981;&#x8BBE;&#x7F6E;spark.sql.pivotMaxValues&#xFF0C;&#x5426;&#x5219;&#x8BA1;&#x7B97;&#x8FC7;&#x7A0B;&#x4E2D;&#x4F1A;&#x51FA;&#x73B0;&#x9519;&#x8BEF;&#x3002;<a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=pivot#pyspark.sql.GroupedData.pivot" target="_blank">&#x6587;&#x6863;&#x4ECB;&#x7ECD;</a>&#x3002;</li>
</ul>
</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x7EDF;&#x8BA1;&#x6BCF;&#x4E2A;&#x7528;&#x6237;&#x5BF9;&#x5404;&#x7C7B;&#x5546;&#x54C1;&#x7684;pv&#x3001;fav&#x3001;cart&#x3001;buy&#x6570;&#x91CF;</span>
cate_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.cateId).pivot(<span class="hljs-string">&quot;btag&quot;</span>,[<span class="hljs-string">&quot;pv&quot;</span>,<span class="hljs-string">&quot;fav&quot;</span>,<span class="hljs-string">&quot;cart&quot;</span>,<span class="hljs-string">&quot;buy&quot;</span>]).count()
cate_count_df.printSchema()    <span class="hljs-comment"># &#x6B64;&#x65F6;&#x8FD8;&#x6CA1;&#x6709;&#x5F00;&#x59CB;&#x8BA1;&#x7B97;</span>
</code></pre>
<p>&#x663E;&#x793A;&#x6548;&#x679C;:</p>
<pre><code class="lang-shell">root
 |-- userId: integer (nullable = true)
 |-- cateId: integer (nullable = true)
 |-- pv: long (nullable = true)
 |-- fav: long (nullable = true)
 |-- cart: long (nullable = true)
 |-- buy: long (nullable = true)
</code></pre>
<ul>
<li>&#x7EDF;&#x8BA1;&#x6BCF;&#x4E2A;&#x7528;&#x6237;&#x5BF9;&#x5404;&#x4E2A;&#x54C1;&#x724C;&#x7684;pv&#x3001;fav&#x3001;cart&#x3001;buy&#x6570;&#x91CF;&#x5E76;&#x4FDD;&#x5B58;&#x7ED3;&#x679C;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x7EDF;&#x8BA1;&#x6BCF;&#x4E2A;&#x7528;&#x6237;&#x5BF9;&#x5404;&#x4E2A;&#x54C1;&#x724C;&#x7684;pv&#x3001;fav&#x3001;cart&#x3001;buy&#x6570;&#x91CF;</span>
brand_count_df = behavior_log_df.groupBy(behavior_log_df.userId, behavior_log_df.brandId).pivot(<span class="hljs-string">&quot;btag&quot;</span>,[<span class="hljs-string">&quot;pv&quot;</span>,<span class="hljs-string">&quot;fav&quot;</span>,<span class="hljs-string">&quot;cart&quot;</span>,<span class="hljs-string">&quot;buy&quot;</span>]).count()
<span class="hljs-comment"># brand_count_df.show()    # &#x540C;&#x4E0A;</span>
<span class="hljs-comment"># 113w * 46w</span>
<span class="hljs-comment"># &#x7531;&#x4E8E;&#x8FD0;&#x7B97;&#x65F6;&#x95F4;&#x6BD4;&#x8F83;&#x957F;&#xFF0C;&#x6240;&#x4EE5;&#x8FD9;&#x91CC;&#x5148;&#x5C06;&#x7ED3;&#x679C;&#x5B58;&#x50A8;&#x8D77;&#x6765;&#xFF0C;&#x4F9B;&#x540E;&#x7EED;&#x5176;&#x4ED6;&#x64CD;&#x4F5C;&#x4F7F;&#x7528;</span>
<span class="hljs-comment"># &#x5199;&#x5165;&#x6570;&#x636E;&#x65F6;&#x624D;&#x5F00;&#x59CB;&#x8BA1;&#x7B97;</span>
cate_count_df.write.csv(<span class="hljs-string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="hljs-keyword">True</span>)
brand_count_df.write.csv(<span class="hljs-string">&quot;hdfs://localhost:9000/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="hljs-keyword">True</span>)
</code></pre>
<h3 id="22-&#x6839;&#x636E;&#x7528;&#x6237;&#x5BF9;&#x7C7B;&#x76EE;&#x504F;&#x597D;&#x6253;&#x5206;&#x8BAD;&#x7EC3;als&#x6A21;&#x578B;">2.2 &#x6839;&#x636E;&#x7528;&#x6237;&#x5BF9;&#x7C7B;&#x76EE;&#x504F;&#x597D;&#x6253;&#x5206;&#x8BAD;&#x7EC3;ALS&#x6A21;&#x578B;</h3>
<ul>
<li>&#x6839;&#x636E;&#x60A8;&#x7EDF;&#x8BA1;&#x7684;&#x6B21;&#x6570; + &#x6253;&#x5206;&#x89C4;&#x5219; ==&gt; &#x504F;&#x597D;&#x6253;&#x5206;&#x6570;&#x636E;&#x96C6; ==&gt; ALS&#x6A21;&#x578B;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># spark ml&#x7684;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x662F;&#x57FA;&#x4E8E;&#x5185;&#x5B58;&#x7684;&#xFF0C;&#x5982;&#x679C;&#x6570;&#x636E;&#x8FC7;&#x5927;&#xFF0C;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x5C0F;&#xFF0C;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x8FC7;&#x591A;&#x7684;&#x5316;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x9020;&#x6210;&#x5185;&#x5B58;&#x6EA2;&#x51FA;&#xFF0C;&#x62A5;&#x9519;</span>
<span class="hljs-comment"># &#x8BBE;&#x7F6E;Checkpoint&#x7684;&#x8BDD;&#xFF0C;&#x4F1A;&#x628A;&#x6240;&#x6709;&#x6570;&#x636E;&#x843D;&#x76D8;&#xFF0C;&#x8FD9;&#x6837;&#x5982;&#x679C;&#x5F02;&#x5E38;&#x9000;&#x51FA;&#xFF0C;&#x4E0B;&#x6B21;&#x91CD;&#x542F;&#x540E;&#xFF0C;&#x53EF;&#x4EE5;&#x63A5;&#x7740;&#x4E0A;&#x6B21;&#x7684;&#x8BAD;&#x7EC3;&#x8282;&#x70B9;&#x7EE7;&#x7EED;&#x8FD0;&#x884C;</span>
<span class="hljs-comment"># &#x4F46;&#x8BE5;&#x65B9;&#x6CD5;&#x5176;&#x5B9E;&#x6307;&#x6807;&#x4E0D;&#x6CBB;&#x672C;&#xFF0C;&#x56E0;&#x4E3A;&#x65E0;&#x6CD5;&#x9632;&#x6B62;&#x5185;&#x5B58;&#x6EA2;&#x51FA;&#xFF0C;&#x6240;&#x4EE5;&#x8FD8;&#x662F;&#x4F1A;&#x62A5;&#x9519;</span>
<span class="hljs-comment"># &#x5982;&#x679C;&#x6570;&#x636E;&#x91CF;&#x5927;&#xFF0C;&#x5E94;&#x8003;&#x8651;&#x7684;&#x662F;&#x589E;&#x52A0;&#x5185;&#x5B58;&#x3001;&#x6216;&#x9650;&#x5236;&#x8FED;&#x4EE3;&#x6B21;&#x6570;&#x548C;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x91CF;&#x7EA7;&#x7B49;</span>
spark.sparkContext.setCheckpointDir(<span class="hljs-string">&quot;hdfs://localhost:9000/checkPoint/&quot;</span>)
<span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> StructType, StructField, StringType, IntegerType, LongType, FloatType

<span class="hljs-comment"># &#x6784;&#x5EFA;&#x7ED3;&#x6784;&#x5BF9;&#x8C61;</span>
schema = StructType([
    StructField(<span class="hljs-string">&quot;userId&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;cateId&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;pv&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;fav&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;cart&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;buy&quot;</span>, IntegerType())
])

<span class="hljs-comment"># &#x4ECE;hdfs&#x52A0;&#x8F7D;CSV&#x6587;&#x4EF6;</span>
cate_count_df = spark.read.csv(<span class="hljs-string">&quot;hdfs://localhost:9000/preprocessing_dataset/cate_count.csv&quot;</span>, header=<span class="hljs-keyword">True</span>, schema=schema)
cate_count_df.printSchema()
cate_count_df.first()    <span class="hljs-comment"># &#x7B2C;&#x4E00;&#x884C;&#x6570;&#x636E;</span>
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">root
 |-- userId: integer (nullable = true)
 |-- cateId: integer (nullable = true)
 |-- pv: integer (nullable = true)
 |-- fav: integer (nullable = true)
 |-- cart: integer (nullable = true)
 |-- buy: integer (nullable = true)

Row(userId=1061650, cateId=4520, pv=2326, fav=None, cart=53, buy=None)
</code></pre>
<ul>
<li>&#x5904;&#x7406;&#x6BCF;&#x4E00;&#x884C;&#x6570;&#x636E;&#xFF1A;r&#x8868;&#x793A;row&#x5BF9;&#x8C61;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_row</span><span class="hljs-params">(r)</span>:</span>
    <span class="hljs-comment"># &#x5904;&#x7406;&#x6BCF;&#x4E00;&#x884C;&#x6570;&#x636E;&#xFF1A;r&#x8868;&#x793A;row&#x5BF9;&#x8C61;</span>

    <span class="hljs-comment"># &#x504F;&#x597D;&#x8BC4;&#x5206;&#x89C4;&#x5219;&#xFF1A;</span>
    <span class="hljs-comment">#     m: &#x7528;&#x6237;&#x5BF9;&#x5E94;&#x7684;&#x884C;&#x4E3A;&#x6B21;&#x6570;</span>
    <span class="hljs-comment">#     &#x8BE5;&#x504F;&#x597D;&#x6743;&#x91CD;&#x6BD4;&#x4F8B;&#xFF0C;&#x6B21;&#x6570;&#x4E0A;&#x9650;&#x4EC5;&#x4F9B;&#x53C2;&#x8003;&#xFF0C;&#x5177;&#x4F53;&#x6570;&#x503C;&#x5E94;&#x6839;&#x636E;&#x4EA7;&#x54C1;&#x4E1A;&#x52A1;&#x573A;&#x666F;&#x6743;&#x8861;</span>
    <span class="hljs-comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span>
    <span class="hljs-comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span>
    <span class="hljs-comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span>
    <span class="hljs-comment">#     buy: if m&lt;=20: score=1*m; else score=20</span>

    <span class="hljs-comment"># &#x6CE8;&#x610F;&#x8FD9;&#x91CC;&#x8981;&#x5168;&#x90E8;&#x8BBE;&#x4E3A;&#x6D6E;&#x70B9;&#x6570;&#xFF0C;spark&#x8FD0;&#x7B97;&#x65F6;&#x5BF9;&#x7C7B;&#x578B;&#x6BD4;&#x8F83;&#x654F;&#x611F;&#xFF0C;&#x8981;&#x4FDD;&#x6301;&#x6570;&#x636E;&#x7C7B;&#x578B;&#x90FD;&#x4E00;&#x81F4;</span>
    pv_count = r.pv <span class="hljs-keyword">if</span> r.pv <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>
    fav_count = r.fav <span class="hljs-keyword">if</span> r.fav <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>
    cart_count = r.cart <span class="hljs-keyword">if</span> r.cart <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>
    buy_count = r.buy <span class="hljs-keyword">if</span> r.buy <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>

    pv_score = <span class="hljs-number">0.2</span>*pv_count <span class="hljs-keyword">if</span> pv_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">4.0</span>
    fav_score = <span class="hljs-number">0.4</span>*fav_count <span class="hljs-keyword">if</span> fav_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">8.0</span>
    cart_score = <span class="hljs-number">0.6</span>*cart_count <span class="hljs-keyword">if</span> cart_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">12.0</span>
    buy_score = <span class="hljs-number">1.0</span>*buy_count <span class="hljs-keyword">if</span> buy_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">20.0</span>

    rating = pv_score + fav_score + cart_score + buy_score
    <span class="hljs-comment"># &#x8FD4;&#x56DE;&#x7528;&#x6237;ID&#x3001;&#x5206;&#x7C7B;ID&#x3001;&#x7528;&#x6237;&#x5BF9;&#x5206;&#x7C7B;&#x7684;&#x504F;&#x597D;&#x6253;&#x5206;</span>
    <span class="hljs-keyword">return</span> r.userId, r.cateId, rating
</code></pre>
<ul>
<li>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;PythonRDD&#x7C7B;&#x578B;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8FD4;&#x56DE;&#x4E00;&#x4E2A;PythonRDD&#x7C7B;&#x578B;&#xFF0C;&#x6B64;&#x65F6;&#x8FD8;&#x6CA1;&#x5F00;&#x59CB;&#x8BA1;&#x7B97;</span>
cate_count_df.rdd.map(process_row).toDF([<span class="hljs-string">&quot;userId&quot;</span>, <span class="hljs-string">&quot;cateId&quot;</span>, <span class="hljs-string">&quot;rating&quot;</span>])
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">DataFrame[userId: bigint, cateId: bigint, rating: double]
</code></pre>
<ul>
<li>&#x7528;&#x6237;&#x5BF9;&#x5546;&#x54C1;&#x7C7B;&#x522B;&#x7684;&#x6253;&#x5206;&#x6570;&#x636E;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x7528;&#x6237;&#x5BF9;&#x5546;&#x54C1;&#x7C7B;&#x522B;&#x7684;&#x6253;&#x5206;&#x6570;&#x636E;</span>
<span class="hljs-comment"># map&#x8FD4;&#x56DE;&#x7684;&#x7ED3;&#x679C;&#x662F;rdd&#x7C7B;&#x578B;&#xFF0C;&#x9700;&#x8981;&#x8C03;&#x7528;toDF&#x65B9;&#x6CD5;&#x8F6C;&#x6362;&#x4E3A;Dataframe</span>
cate_rating_df = cate_count_df.rdd.map(process_row).toDF([<span class="hljs-string">&quot;userId&quot;</span>, <span class="hljs-string">&quot;cateId&quot;</span>, <span class="hljs-string">&quot;rating&quot;</span>])
<span class="hljs-comment"># &#x6CE8;&#x610F;&#xFF1A;toDF&#x4E0D;&#x662F;&#x6BCF;&#x4E2A;rdd&#x90FD;&#x6709;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x4EC5;&#x5C40;&#x9650;&#x4E8E;&#x6B64;&#x5904;&#x7684;rdd</span>
<span class="hljs-comment"># &#x53EF;&#x901A;&#x8FC7;&#x8BE5;&#x65B9;&#x6CD5;&#x83B7;&#x5F97; user-cate-matrix</span>
<span class="hljs-comment"># &#x4F46;&#x7531;&#x4E8E;cateId&#x5B57;&#x6BB5;&#x8FC7;&#x591A;&#xFF0C;&#x8FD9;&#x91CC;&#x8FD0;&#x7B97;&#x91CF;&#x6BD4;&#x5F88;&#x5927;&#xFF0C;&#x673A;&#x5668;&#x5185;&#x5B58;&#x8981;&#x6C42;&#x5F88;&#x9AD8;&#x624D;&#x80FD;&#x6267;&#x884C;&#xFF0C;&#x5426;&#x5219;&#x65E0;&#x6CD5;&#x5B8C;&#x6210;&#x4EFB;&#x52A1;</span>
<span class="hljs-comment"># &#x8BF7;&#x8C28;&#x614E;&#x4F7F;&#x7528;</span>

<span class="hljs-comment"># &#x4F46;&#x597D;&#x5728;&#x6211;&#x4EEC;&#x8BAD;&#x7EC3;ALS&#x6A21;&#x578B;&#x65F6;&#xFF0C;&#x4E0D;&#x9700;&#x8981;&#x8F6C;&#x6362;&#x4E3A;user-cate-matrix&#xFF0C;&#x6240;&#x4EE5;&#x8FD9;&#x91CC;&#x53EF;&#x4EE5;&#x4E0D;&#x7528;&#x8FD0;&#x884C;</span>
<span class="hljs-comment"># cate_rating_df.groupBy(&quot;userId&quot;).povit(&quot;cateId&quot;).min(&quot;rating&quot;)</span>
<span class="hljs-comment"># &#x7528;&#x6237;&#x5BF9;&#x7C7B;&#x522B;&#x7684;&#x504F;&#x597D;&#x6253;&#x5206;&#x6570;&#x636E;</span>
cate_rating_df
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code>DataFrame[userId: bigint, cateId: bigint, rating: double]
</code></pre><ul>
<li>&#x901A;&#x5E38;&#x5982;&#x679C;USER-ITEM&#x6253;&#x5206;&#x6570;&#x636E;&#x5E94;&#x8BE5;&#x662F;&#x901A;&#x8FC7;&#x4E00;&#x4E0B;&#x65B9;&#x5F0F;&#x8FDB;&#x884C;&#x5904;&#x7406;&#x8F6C;&#x6362;&#x4E3A;USER-ITEM-MATRIX</li>
</ul>
<p><img src="img/CF%E4%BB%8B%E7%BB%8D.png" alt=""></p>
<p>&#x4F46;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x5C06;&#x4F7F;&#x7528;&#x7684;Spark&#x7684;ALS&#x6A21;&#x578B;&#x8FDB;&#x884C;CF&#x63A8;&#x8350;&#xFF0C;&#x56E0;&#x6B64;&#x6CE8;&#x610F;&#x8FD9;&#x91CC;&#x6570;&#x636E;&#x8F93;&#x5165;&#x4E0D;&#x9700;&#x8981;&#x63D0;&#x524D;&#x8F6C;&#x6362;&#x4E3A;&#x77E9;&#x9635;&#xFF0C;&#x76F4;&#x63A5;&#x662F; USER-ITEM-RATE&#x7684;&#x6570;&#x636E;</p>
<ul>
<li><p>&#x57FA;&#x4E8E;Spark&#x7684;ALS&#x9690;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#x8FDB;&#x884C;CF&#x8BC4;&#x5206;&#x9884;&#x6D4B;</p>
<ul>
<li><p>ALS&#x7684;&#x610F;&#x601D;&#x662F;&#x4EA4;&#x66FF;&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;&#xFF08;Alternating Least Squares&#xFF09;&#xFF0C;&#x662F;Spark2.*&#x4E2D;&#x52A0;&#x5165;&#x7684;&#x8FDB;&#x884C;&#x57FA;&#x4E8E;&#x6A21;&#x578B;&#x7684;&#x534F;&#x540C;&#x8FC7;&#x6EE4;&#xFF08;model-based CF&#xFF09;&#x7684;&#x63A8;&#x8350;&#x7CFB;&#x7EDF;&#x7B97;&#x6CD5;&#x3002;</p>
<p>&#x540C;SVD&#xFF0C;&#x5B83;&#x4E5F;&#x662F;&#x4E00;&#x79CD;&#x77E9;&#x9635;&#x5206;&#x89E3;&#x6280;&#x672F;&#xFF0C;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x964D;&#x7EF4;&#x5904;&#x7406;&#x3002;</p>
</li>
<li><p>&#x8BE6;&#x7EC6;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#xFF1A;<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation" target="_blank">pyspark.ml.recommendation.ALS</a></p>
</li>
<li><p>&#x6CE8;&#x610F;&#xFF1A;&#x7531;&#x4E8E;&#x6570;&#x636E;&#x91CF;&#x5DE8;&#x5927;&#xFF0C;&#x56E0;&#x6B64;&#x8FD9;&#x91CC;&#x4E5F;&#x4E0D;&#x8003;&#x8651;&#x57FA;&#x4E8E;&#x5185;&#x5B58;&#x7684;CF&#x7B97;&#x6CD5;</p>
<p>&#x53C2;&#x8003;&#xFF1A;<a href="https://www.cnblogs.com/mooba/p/6539142.html" target="_blank">&#x4E3A;&#x4EC0;&#x4E48;Spark&#x4E2D;&#x53EA;&#x6709;ALS</a></p>
</li>
</ul>
</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528;pyspark&#x4E2D;&#x7684;ALS&#x77E9;&#x9635;&#x5206;&#x89E3;&#x65B9;&#x6CD5;&#x5B9E;&#x73B0;CF&#x8BC4;&#x5206;&#x9884;&#x6D4B;</span>
<span class="hljs-comment"># &#x6587;&#x6863;&#x5730;&#x5740;&#xFF1A;https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span>
<span class="hljs-keyword">from</span> pyspark.ml.recommendation <span class="hljs-keyword">import</span> ALS   <span class="hljs-comment"># ml&#xFF1A;dataframe&#xFF0C; mllib&#xFF1A;rdd</span>

<span class="hljs-comment"># &#x5229;&#x7528;&#x6253;&#x5206;&#x6570;&#x636E;&#xFF0C;&#x8BAD;&#x7EC3;ALS&#x6A21;&#x578B;</span>
als = ALS(userCol=<span class="hljs-string">&apos;userId&apos;</span>, itemCol=<span class="hljs-string">&apos;cateId&apos;</span>, ratingCol=<span class="hljs-string">&apos;rating&apos;</span>, checkpointInterval=<span class="hljs-number">5</span>)

<span class="hljs-comment"># &#x6B64;&#x5904;&#x8BAD;&#x7EC3;&#x65F6;&#x95F4;&#x8F83;&#x957F;</span>
model = als.fit(cate_rating_df)
</code></pre>
<ul>
<li>&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x597D;&#x540E;&#xFF0C;&#x8C03;&#x7528;&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x4F7F;&#x7528;&#xFF0C;<a href="https://spark.apache.org/docs/2.2.2/api/python/pyspark.ml.html?highlight=alsmodel#pyspark.ml.recommendation.ALSModel" target="_blank">&#x5177;&#x4F53;API&#x67E5;&#x770B;</a></li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># model.recommendForAllUsers(N) &#x7ED9;&#x6240;&#x6709;&#x7528;&#x6237;&#x63A8;&#x8350;TOP-N&#x4E2A;&#x7269;&#x54C1;</span>
ret = model.recommendForAllUsers(<span class="hljs-number">3</span>)
<span class="hljs-comment"># &#x7531;&#x4E8E;&#x662F;&#x7ED9;&#x6240;&#x6709;&#x7528;&#x6237;&#x8FDB;&#x884C;&#x63A8;&#x8350;&#xFF0C;&#x6B64;&#x5904;&#x8FD0;&#x7B97;&#x65F6;&#x95F4;&#x4E5F;&#x8F83;&#x957F;</span>
ret.show()
<span class="hljs-comment"># &#x63A8;&#x8350;&#x7ED3;&#x679C;&#x5B58;&#x653E;&#x5728;recommendations&#x5217;&#x4E2D;&#xFF0C;</span>
ret.select(<span class="hljs-string">&quot;recommendations&quot;</span>).show()
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">+------+--------------------+
|userId|     recommendations|
+------+--------------------+
|   148|[[3347, 12.547271...|
|   463|[[1610, 9.250818]...|
|   471|[[1610, 10.246621...|
|   496|[[1610, 5.162216]...|
|   833|[[5607, 9.065482]...|
|  1088|[[104, 6.886987],...|
|  1238|[[5631, 14.51981]...|
|  1342|[[5720, 10.89842]...|
|  1580|[[5731, 8.466453]...|
|  1591|[[1610, 12.835257...|
|  1645|[[1610, 11.968531...|
|  1829|[[1610, 17.576496...|
|  1959|[[1610, 8.353473]...|
|  2122|[[1610, 12.652732...|
|  2142|[[1610, 12.48068]...|
|  2366|[[1610, 11.904813...|
|  2659|[[5607, 11.699315...|
|  2866|[[1610, 7.752719]...|
|  3175|[[3347, 2.3429515...|
|  3749|[[1610, 3.641833]...|
+------+--------------------+
only showing top 20 rows

+--------------------+
|     recommendations|
+--------------------+
|[[3347, 12.547271...|
|[[1610, 9.250818]...|
|[[1610, 10.246621...|
|[[1610, 5.162216]...|
|[[5607, 9.065482]...|
|[[104, 6.886987],...|
|[[5631, 14.51981]...|
|[[5720, 10.89842]...|
|[[5731, 8.466453]...|
|[[1610, 12.835257...|
|[[1610, 11.968531...|
|[[1610, 17.576496...|
|[[1610, 8.353473]...|
|[[1610, 12.652732...|
|[[1610, 12.48068]...|
|[[1610, 11.904813...|
|[[5607, 11.699315...|
|[[1610, 7.752719]...|
|[[3347, 2.3429515...|
|[[1610, 3.641833]...|
+--------------------+
only showing top 20 rows
</code></pre>
<ul>
<li>model.recommendForUserSubset &#x7ED9;&#x90E8;&#x5206;&#x7528;&#x6237;&#x63A8;&#x8350;TOP-N&#x4E2A;&#x7269;&#x54C1;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6CE8;&#x610F;&#xFF1A;recommendForUserSubset API&#xFF0C;2.2.2&#x7248;&#x672C;&#x4E2D;&#x65E0;&#x6CD5;&#x4F7F;&#x7528;</span>
dataset = spark.createDataFrame([[<span class="hljs-number">1</span>],[<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>]])
dataset = dataset.withColumnRenamed(<span class="hljs-string">&quot;_1&quot;</span>, <span class="hljs-string">&quot;userId&quot;</span>)
ret = model.recommendForUserSubset(dataset, <span class="hljs-number">3</span>)

<span class="hljs-comment"># &#x53EA;&#x7ED9;&#x90E8;&#x5206;&#x7528;&#x63A8;&#x8350;&#xFF0C;&#x8FD0;&#x7B97;&#x65F6;&#x95F4;&#x77ED;</span>
ret.show()
ret.collect()    <span class="hljs-comment"># &#x6CE8;&#x610F;&#xFF1A; collect&#x4F1A;&#x5C06;&#x6240;&#x6709;&#x6570;&#x636E;&#x52A0;&#x8F7D;&#x5230;&#x5185;&#x5B58;&#xFF0C;&#x614E;&#x7528;</span>
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">+------+--------------------+
|userId|     recommendations|
+------+--------------------+
|     1|[[1610, 25.4989],...|
|     3|[[5607, 13.665942...|
|     2|[[5579, 5.9051886...|
+------+--------------------+

[Row(userId=1, recommendations=[Row(cateId=1610, rating=25.498899459838867), Row(cateId=5737, rating=24.901548385620117), Row(cateId=3347, rating=20.736785888671875)]),
 Row(userId=3, recommendations=[Row(cateId=5607, rating=13.665942192077637), Row(cateId=1610, rating=11.770171165466309), Row(cateId=3347, rating=10.35690689086914)]),
 Row(userId=2, recommendations=[Row(cateId=5579, rating=5.90518856048584), Row(cateId=2447, rating=5.624575138092041), Row(cateId=5690, rating=5.2555742263793945)])]
</code></pre>
<ul>
<li>transform&#x4E2D;&#x63D0;&#x4F9B;userId&#x548C;cateId&#x53EF;&#x4EE5;&#x5BF9;&#x6253;&#x5206;&#x8FDB;&#x884C;&#x9884;&#x6D4B;&#xFF0C;&#x5229;&#x7528;&#x6253;&#x5206;&#x7ED3;&#x679C;&#x6392;&#x5E8F;&#x540E;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># transform&#x4E2D;&#x63D0;&#x4F9B;userId&#x548C;cateId&#x53EF;&#x4EE5;&#x5BF9;&#x6253;&#x5206;&#x8FDB;&#x884C;&#x9884;&#x6D4B;&#xFF0C;&#x5229;&#x7528;&#x6253;&#x5206;&#x7ED3;&#x679C;&#x6392;&#x5E8F;&#x540E;&#xFF0C;&#x540C;&#x6837;&#x53EF;&#x4EE5;&#x5B9E;&#x73B0;TOP-N&#x7684;&#x63A8;&#x8350;</span>
model.transform
<span class="hljs-comment"># &#x5C06;&#x6A21;&#x578B;&#x8FDB;&#x884C;&#x5B58;&#x50A8;</span>
model.save(<span class="hljs-string">&quot;hdfs://localhost:9000/models/userCateRatingALSModel.obj&quot;</span>)
<span class="hljs-comment"># &#x6D4B;&#x8BD5;&#x5B58;&#x50A8;&#x7684;&#x6A21;&#x578B;</span>
<span class="hljs-keyword">from</span> pyspark.ml.recommendation <span class="hljs-keyword">import</span> ALSModel
<span class="hljs-comment"># &#x4ECE;hdfs&#x52A0;&#x8F7D;&#x4E4B;&#x524D;&#x5B58;&#x50A8;&#x7684;&#x6A21;&#x578B;</span>
als_model = ALSModel.load(<span class="hljs-string">&quot;hdfs://localhost:9000/models/userCateRatingALSModel.obj&quot;</span>)
<span class="hljs-comment"># model.recommendForAllUsers(N) &#x7ED9;&#x7528;&#x6237;&#x63A8;&#x8350;TOP-N&#x4E2A;&#x7269;&#x54C1;</span>
result = als_model.recommendForAllUsers(<span class="hljs-number">3</span>)
result.show()
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">+------+--------------------+
|userId|     recommendations|
+------+--------------------+
|   148|[[3347, 12.547271...|
|   463|[[1610, 9.250818]...|
|   471|[[1610, 10.246621...|
|   496|[[1610, 5.162216]...|
|   833|[[5607, 9.065482]...|
|  1088|[[104, 6.886987],...|
|  1238|[[5631, 14.51981]...|
|  1342|[[5720, 10.89842]...|
|  1580|[[5731, 8.466453]...|
|  1591|[[1610, 12.835257...|
|  1645|[[1610, 11.968531...|
|  1829|[[1610, 17.576496...|
|  1959|[[1610, 8.353473]...|
|  2122|[[1610, 12.652732...|
|  2142|[[1610, 12.48068]...|
|  2366|[[1610, 11.904813...|
|  2659|[[5607, 11.699315...|
|  2866|[[1610, 7.752719]...|
|  3175|[[3347, 2.3429515...|
|  3749|[[1610, 3.641833]...|
+------+--------------------+
only showing top 20 rows
</code></pre>
<ul>
<li>&#x53EC;&#x56DE;&#x5230;redis</li>
</ul>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> redis
host = <span class="hljs-string">&quot;192.168.19.137&quot;</span>
port = <span class="hljs-number">6379</span>    
<span class="hljs-comment"># &#x53EC;&#x56DE;&#x5230;redis</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">recall_cate_by_cf</span><span class="hljs-params">(partition)</span>:</span>
    <span class="hljs-comment"># &#x5EFA;&#x7ACB;redis &#x8FDE;&#x63A5;&#x6C60;</span>
    pool = redis.ConnectionPool(host=host, port=port)
    <span class="hljs-comment"># &#x5EFA;&#x7ACB;redis&#x5BA2;&#x6237;&#x7AEF;</span>
    client = redis.Redis(connection_pool=pool)
    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> partition:
        client.hset(<span class="hljs-string">&quot;recall_cate&quot;</span>, row.userId, [i.cateId <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> row.recommendations])
<span class="hljs-comment"># &#x5BF9;&#x6BCF;&#x4E2A;&#x5206;&#x7247;&#x7684;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x5904;&#x7406; #mapPartitions Transformation   map</span>
<span class="hljs-comment"># foreachPartition Action&#x64CD;&#x4F5C;             foreachRDD</span>
result.foreachPartition(recall_cate_by_cf)

<span class="hljs-comment"># &#x6CE8;&#x610F;&#xFF1A;&#x8FD9;&#x91CC;&#x8FD9;&#x662F;&#x53EC;&#x56DE;&#x7684;&#x662F;&#x7528;&#x6237;&#x6700;&#x611F;&#x5174;&#x8DA3;&#x7684;n&#x4E2A;&#x7C7B;&#x522B;</span>
<span class="hljs-comment"># &#x603B;&#x7684;&#x6761;&#x76EE;&#x6570;&#xFF0C;&#x67E5;&#x770B;redis&#x4E2D;&#x603B;&#x7684;&#x6761;&#x76EE;&#x6570;&#x662F;&#x5426;&#x4E00;&#x81F4;</span>
result.count()
</code></pre>
<p>&#x663E;&#x793A;&#x7ED3;&#x679C;:</p>
<pre><code class="lang-shell">1136340
</code></pre>
<h3 id="23-&#x6839;&#x636E;&#x7528;&#x6237;&#x5BF9;&#x54C1;&#x724C;&#x504F;&#x597D;&#x6253;&#x5206;&#x8BAD;&#x7EC3;als&#x6A21;&#x578B;">2.3 &#x6839;&#x636E;&#x7528;&#x6237;&#x5BF9;&#x54C1;&#x724C;&#x504F;&#x597D;&#x6253;&#x5206;&#x8BAD;&#x7EC3;ALS&#x6A21;&#x578B;</h3>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> pyspark.sql.types <span class="hljs-keyword">import</span> StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField(<span class="hljs-string">&quot;userId&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;brandId&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;pv&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;fav&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;cart&quot;</span>, IntegerType()),
    StructField(<span class="hljs-string">&quot;buy&quot;</span>, IntegerType())
])
<span class="hljs-comment"># &#x4ECE;hdfs&#x52A0;&#x8F7D;&#x9884;&#x5904;&#x7406;&#x597D;&#x7684;&#x54C1;&#x724C;&#x7684;&#x7EDF;&#x8BA1;&#x6570;&#x636E;</span>
brand_count_df = spark.read.csv(<span class="hljs-string">&quot;hdfs://localhost:9000/preprocessing_dataset/brand_count.csv&quot;</span>, header=<span class="hljs-keyword">True</span>, schema=schema)
<span class="hljs-comment"># brand_count_df.show()</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_row</span><span class="hljs-params">(r)</span>:</span>
    <span class="hljs-comment"># &#x5904;&#x7406;&#x6BCF;&#x4E00;&#x884C;&#x6570;&#x636E;&#xFF1A;r&#x8868;&#x793A;row&#x5BF9;&#x8C61;</span>

    <span class="hljs-comment"># &#x504F;&#x597D;&#x8BC4;&#x5206;&#x89C4;&#x5219;&#xFF1A;</span>
    <span class="hljs-comment">#     m: &#x7528;&#x6237;&#x5BF9;&#x5E94;&#x7684;&#x884C;&#x4E3A;&#x6B21;&#x6570;</span>
    <span class="hljs-comment">#     &#x8BE5;&#x504F;&#x597D;&#x6743;&#x91CD;&#x6BD4;&#x4F8B;&#xFF0C;&#x6B21;&#x6570;&#x4E0A;&#x9650;&#x4EC5;&#x4F9B;&#x53C2;&#x8003;&#xFF0C;&#x5177;&#x4F53;&#x6570;&#x503C;&#x5E94;&#x6839;&#x636E;&#x4EA7;&#x54C1;&#x4E1A;&#x52A1;&#x573A;&#x666F;&#x6743;&#x8861;</span>
    <span class="hljs-comment">#     pv: if m&lt;=20: score=0.2*m; else score=4</span>
    <span class="hljs-comment">#     fav: if m&lt;=20: score=0.4*m; else score=8</span>
    <span class="hljs-comment">#     cart: if m&lt;=20: score=0.6*m; else score=12</span>
    <span class="hljs-comment">#     buy: if m&lt;=20: score=1*m; else score=20</span>

    <span class="hljs-comment"># &#x6CE8;&#x610F;&#x8FD9;&#x91CC;&#x8981;&#x5168;&#x90E8;&#x8BBE;&#x4E3A;&#x6D6E;&#x70B9;&#x6570;&#xFF0C;spark&#x8FD0;&#x7B97;&#x65F6;&#x5BF9;&#x7C7B;&#x578B;&#x6BD4;&#x8F83;&#x654F;&#x611F;&#xFF0C;&#x8981;&#x4FDD;&#x6301;&#x6570;&#x636E;&#x7C7B;&#x578B;&#x90FD;&#x4E00;&#x81F4;</span>
    pv_count = r.pv <span class="hljs-keyword">if</span> r.pv <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>
    fav_count = r.fav <span class="hljs-keyword">if</span> r.fav <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>
    cart_count = r.cart <span class="hljs-keyword">if</span> r.cart <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>
    buy_count = r.buy <span class="hljs-keyword">if</span> r.buy <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>

    pv_score = <span class="hljs-number">0.2</span>*pv_count <span class="hljs-keyword">if</span> pv_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">4.0</span>
    fav_score = <span class="hljs-number">0.4</span>*fav_count <span class="hljs-keyword">if</span> fav_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">8.0</span>
    cart_score = <span class="hljs-number">0.6</span>*cart_count <span class="hljs-keyword">if</span> cart_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">12.0</span>
    buy_score = <span class="hljs-number">1.0</span>*buy_count <span class="hljs-keyword">if</span> buy_count&lt;=<span class="hljs-number">20</span> <span class="hljs-keyword">else</span> <span class="hljs-number">20.0</span>

    rating = pv_score + fav_score + cart_score + buy_score
    <span class="hljs-comment"># &#x8FD4;&#x56DE;&#x7528;&#x6237;ID&#x3001;&#x54C1;&#x724C;ID&#x3001;&#x7528;&#x6237;&#x5BF9;&#x54C1;&#x724C;&#x7684;&#x504F;&#x597D;&#x6253;&#x5206;</span>
    <span class="hljs-keyword">return</span> r.userId, r.brandId, rating
<span class="hljs-comment"># &#x7528;&#x6237;&#x5BF9;&#x54C1;&#x724C;&#x7684;&#x6253;&#x5206;&#x6570;&#x636E;</span>
brand_rating_df = brand_count_df.rdd.map(process_row).toDF([<span class="hljs-string">&quot;userId&quot;</span>, <span class="hljs-string">&quot;brandId&quot;</span>, <span class="hljs-string">&quot;rating&quot;</span>])
<span class="hljs-comment"># brand_rating_df.show()</span>
</code></pre>
<ul>
<li><p>&#x57FA;&#x4E8E;Spark&#x7684;ALS&#x9690;&#x56E0;&#x5B50;&#x6A21;&#x578B;&#x8FDB;&#x884C;CF&#x8BC4;&#x5206;&#x9884;&#x6D4B;</p>
<ul>
<li><p>ALS&#x7684;&#x610F;&#x601D;&#x662F;&#x4EA4;&#x66FF;&#x6700;&#x5C0F;&#x4E8C;&#x4E58;&#x6CD5;&#xFF08;Alternating Least Squares&#xFF09;&#xFF0C;&#x662F;Spark&#x4E2D;&#x8FDB;&#x884C;&#x57FA;&#x4E8E;&#x6A21;&#x578B;&#x7684;&#x534F;&#x540C;&#x8FC7;&#x6EE4;&#xFF08;model-based CF&#xFF09;&#x7684;&#x63A8;&#x8350;&#x7CFB;&#x7EDF;&#x7B97;&#x6CD5;&#xFF0C;&#x4E5F;&#x662F;&#x76EE;&#x524D;Spark&#x5185;&#x552F;&#x4E00;&#x4E00;&#x4E2A;&#x63A8;&#x8350;&#x7B97;&#x6CD5;&#x3002;</p>
<p>&#x540C;SVD&#xFF0C;&#x5B83;&#x4E5F;&#x662F;&#x4E00;&#x79CD;&#x77E9;&#x9635;&#x5206;&#x89E3;&#x6280;&#x672F;&#xFF0C;&#x4F46;&#x7406;&#x8BBA;&#x4E0A;&#xFF0C;ALS&#x5728;&#x6D77;&#x91CF;&#x6570;&#x636E;&#x7684;&#x5904;&#x7406;&#x4E0A;&#x8981;&#x4F18;&#x4E8E;SVD&#x3002;</p>
<p>&#x66F4;&#x591A;&#x4E86;&#x89E3;&#xFF1A;<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation" target="_blank">pyspark.ml.recommendation.ALS</a></p>
<p>&#x6CE8;&#x610F;&#xFF1A;&#x7531;&#x4E8E;&#x6570;&#x636E;&#x91CF;&#x5DE8;&#x5927;&#xFF0C;&#x56E0;&#x6B64;&#x8FD9;&#x91CC;&#x4E0D;&#x8003;&#x8651;&#x57FA;&#x4E8E;&#x5185;&#x5B58;&#x7684;CF&#x7B97;&#x6CD5;</p>
<p>&#x53C2;&#x8003;&#xFF1A;<a href="https://www.cnblogs.com/mooba/p/6539142.html" target="_blank">&#x4E3A;&#x4EC0;&#x4E48;Spark&#x4E2D;&#x53EA;&#x6709;ALS</a></p>
</li>
</ul>
</li>
<li><p>&#x4F7F;&#x7528;pyspark&#x4E2D;&#x7684;ALS&#x77E9;&#x9635;&#x5206;&#x89E3;&#x65B9;&#x6CD5;&#x5B9E;&#x73B0;CF&#x8BC4;&#x5206;&#x9884;&#x6D4B;</p>
</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528;pyspark&#x4E2D;&#x7684;ALS&#x77E9;&#x9635;&#x5206;&#x89E3;&#x65B9;&#x6CD5;&#x5B9E;&#x73B0;CF&#x8BC4;&#x5206;&#x9884;&#x6D4B;</span>
<span class="hljs-comment"># &#x6587;&#x6863;&#x5730;&#x5740;&#xFF1A;https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=vectors#module-pyspark.ml.recommendation</span>
<span class="hljs-keyword">from</span> pyspark.ml.recommendation <span class="hljs-keyword">import</span> ALS

als = ALS(userCol=<span class="hljs-string">&apos;userId&apos;</span>, itemCol=<span class="hljs-string">&apos;brandId&apos;</span>, ratingCol=<span class="hljs-string">&apos;rating&apos;</span>, checkpointInterval=<span class="hljs-number">2</span>)
<span class="hljs-comment"># &#x5229;&#x7528;&#x6253;&#x5206;&#x6570;&#x636E;&#xFF0C;&#x8BAD;&#x7EC3;ALS&#x6A21;&#x578B;</span>
<span class="hljs-comment"># &#x6B64;&#x5904;&#x8BAD;&#x7EC3;&#x65F6;&#x95F4;&#x8F83;&#x957F;</span>
model = als.fit(brand_rating_df)
<span class="hljs-comment"># model.recommendForAllUsers(N) &#x7ED9;&#x7528;&#x6237;&#x63A8;&#x8350;TOP-N&#x4E2A;&#x7269;&#x54C1;</span>
model.recommendForAllUsers(<span class="hljs-number">3</span>).show()
<span class="hljs-comment"># &#x5C06;&#x6A21;&#x578B;&#x8FDB;&#x884C;&#x5B58;&#x50A8;</span>
model.save(<span class="hljs-string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)
<span class="hljs-comment"># &#x6D4B;&#x8BD5;&#x5B58;&#x50A8;&#x7684;&#x6A21;&#x578B;</span>
<span class="hljs-keyword">from</span> pyspark.ml.recommendation <span class="hljs-keyword">import</span> ALSModel
<span class="hljs-comment"># &#x4ECE;hdfs&#x52A0;&#x8F7D;&#x6A21;&#x578B;</span>
my_model = ALSModel.load(<span class="hljs-string">&quot;hdfs://localhost:9000/models/userBrandRatingModel.obj&quot;</span>)
my_model
<span class="hljs-comment"># model.recommendForAllUsers(N) &#x7ED9;&#x7528;&#x6237;&#x63A8;&#x8350;TOP-N&#x4E2A;&#x7269;&#x54C1;</span>
my_model.recommendForAllUsers(<span class="hljs-number">3</span>).first()
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="01_个性化电商广告推荐系统介绍.html" class="navigation navigation-prev " aria-label="Previous page: 01_个性化电商广告推荐系统介绍">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="03_CTR预估数据准备.html" class="navigation navigation-next " aria-label="Next page: 03_CTR预估数据准备">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"02_根据用户行为数据创建ALS模型并召回商品","level":"14.2","depth":1,"next":{"title":"03_CTR预估数据准备","level":"14.3","depth":1,"path":"day07_推荐系统案例/03_CTR预估数据准备.md","ref":"day07_推荐系统案例/03_CTR预估数据准备.md","articles":[]},"previous":{"title":"01_个性化电商广告推荐系统介绍","level":"14.1","depth":1,"path":"day07_推荐系统案例/01_个性化电商广告推荐系统介绍.md","ref":"day07_推荐系统案例/01_个性化电商广告推荐系统介绍.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax","expandable-chapters-small","splitter"],"pluginsConfig":{"splitter":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"expandable-chapters-small":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"day07_推荐系统案例/02_根据用户行为数据创建ALS模型并召回商品.md","mtime":"2019-06-11T10:49:21.784Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-06-16T09:41:09.142Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

